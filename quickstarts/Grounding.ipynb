{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_lgX9omPXF-"
      },
      "source": [
        "## Gemini API: Getting started with information grounding for Gemini models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkR4fWudrHCs"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDKKNfXWrHgs"
      },
      "source": [
        "In this notebook you will learn how to use information grounding with [Gemini models](https://ai.google.dev/gemini-api/docs/models/).\n",
        "\n",
        "Information grounding is the process of connecting these models to specific, verifiable information sources to enhance the accuracy, relevance, and factual correctness of their responses. While LLMs are trained on vast amounts of data, this knowledge can be general, outdated, or lack specific context for particular tasks or domains. Grounding helps to bridge this gap by providing the LLM with access to curated, up-to-date information.\n",
        "\n",
        "Here you will experiment with:\n",
        "- Grounding information using <a href=\"#search_grounding\">Google Search grounding</a>\n",
        "- Adding <a href=\"#yt_links\">YouTube links</a> to gather context information to your prompt\n",
        "- Using <a href=\"#url_context\">URL context</a> to include website, pdf or image URLs as context to your prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKu1tRBrQ7xj"
      },
      "source": [
        "## Set up the SDK and the client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIWKUlPqP5NK"
      },
      "source": [
        "### Install SDK\n",
        "\n",
        "This guide uses the [`google-genai`](https://pypi.org/project/google-genai) Python SDK to connect to the Gemini models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6Fr84vJuPSHb"
      },
      "outputs": [],
      "source": [
        "# Grounding with Google Maps was introduced in 1.43\n",
        "%pip install -q -U \"google-genai>=1.43.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a503bnWNQoCL"
      },
      "source": [
        "### Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RjvgYmdLQd5s"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhKXgMSNQrrV"
      },
      "source": [
        "### Select model and initialize SDK client\n",
        "\n",
        "Select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](./Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "C75s1LR9QmOz"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "MODEL_ID = \"gemini-2.5-flash\"  # @param [\"gemini-2.5-flash-lite\", \"gemini-2.5-flash-lite-preview-09-2025\", \"gemini-2.5-flash\", \"gemini-2.5-flash-preview-09-2025\", \"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mDMScex1It5"
      },
      "source": [
        "## Use Google Search grounding\n",
        "\n",
        "<a name=\"search_grounding\"></a>\n",
        "\n",
        "Google Search grounding is particularly useful for queries that require current information or external knowledge. Using Google Search, Gemini can access nearly real-time information and better responses.\n",
        "\n",
        "To enable Google Search, simply add the `google_search` tool in the `generate_content`'s `config` that way:\n",
        "```\n",
        "    config={\n",
        "      \"tools\": [\n",
        "        {\n",
        "          \"google_search\": {}\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FHIcazUO0-xU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "1a5e7872-0a34-4b10-812a-cf3de906fb85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Response**:\n The latest fully concluded Indian Premier League (IPL) match was the final of the IPL 2024 season, which took place on May 26, 2024.\n\nIn this match, the Kolkata Knight Riders (KKR) faced Sunrisers Hyderabad (SRH) at the M. A. Chidambaram Stadium in Chennai. Sunrisers Hyderabad won the toss and chose to bat first, scoring 113 runs in 18.3 overs. The Kolkata Knight Riders then successfully chased this target in 10.3 overs, winning by eight wickets.\n\nTherefore, the **Kolkata Knight Riders** won the latest Indian Premier League match. This victory secured their third IPL title. Mitchell Starc of KKR was awarded Player of the Match."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search Query: ['latest Indian Premier League match and winner', 'IPL 2024 final match winner']\n",
            "Search Pages: wikipedia.org, iplt20.com\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEJdCQrZcUfKLeqUvHo7RY0lg-A6Na0KTyn1y4jfICc6LlIUyPwOnULklbAV5EGrUggNJe-n_M7ywn4YodbwbRHdWr5a68-84TOVumzld7HtheO21EuOYQH24Yjf9MLVzX72juo5e8oKx5d0RQ15G_jgB7ciWq8BoACJUP6fLWrVgjISPmOxj6Y7EgDWIBujDfIOC3ZaPzsO_yQqSeO\">IPL 2024 final match winner</a>\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEmWIt3OBm-MwhLa8OAoD9yj6duEvkBlgA97fHVW3Rwl5Y0h3iBTAT45kEsPmFeHFSi88PQfA_FZBc_JQIjK7VcBllfBWtb-us46L4C0RvF03SjXEPfezSJSIwEGMyuFpoF9rMXelRK5TabNancuNW650Jo8plq5yGs-iUKNCjM9E9EtYKcCyKvCy5KDdc2AeXQrvgYs4G48d5LoWEMIglcZhqGff_6Rg59_3q60xWB\">latest Indian Premier League match and winner</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import HTML, Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What was the latest Indian Premier League match and who won?\",\n",
        "    config={\"tools\": [{\"google_search\": {}}]},\n",
        ")\n",
        "\n",
        "# print the response\n",
        "display(Markdown(f\"**Response**:\\n {response.text}\"))\n",
        "# print the search details\n",
        "print(f\"Search Query: {response.candidates[0].grounding_metadata.web_search_queries}\")\n",
        "# urls used for grounding\n",
        "print(f\"Search Pages: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")\n",
        "\n",
        "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wROLHEYLLBHX"
      },
      "source": [
        "You can see that running the same prompt without search grounding gives you outdated information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EdUkQ40cKaGX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3d6d03b5-f1ee-4001-a629-0957948b8255"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The latest Indian Premier League match was the **final of the IPL 2024 season**, which took place on **May 26, 2024**.\n\n**Teams:** Kolkata Knight Riders (KKR) vs. Sunrisers Hyderabad (SRH)\n**Winner:** **Kolkata Knight Riders (KKR)** won by 8 wickets."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What was the latest Indian Premier League match and who won?\",\n",
        ")\n",
        "\n",
        "# print the response\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE6Ft1wxSxO_"
      },
      "source": [
        "For more examples, please refer to the [dedicated notebook](./Search_Grounding.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylPa8XFoYCq_"
      },
      "source": [
        "## Use Google Maps grounding\n",
        "\n",
        "Google Maps grounding allows you to easily incorporate location-aware functionality into your applications. When a prompt has context related to Maps data, the Gemini model uses Google Maps to provide factually accurate and fresh answers that are relevant to the specified location or general area.\n",
        "\n",
        "To enable grounding with Google Maps, add the `google_maps` tool in the  `config` argument of `generate_content`, and optionally provide a structured location in the `tool_config`.\n",
        "\n",
        "```python\n",
        "client.models.generate_content(\n",
        "    ...,\n",
        "    config=types.GenerateContentConfig(\n",
        "      # Enable the tool.\n",
        "      tools=[types.Tool(google_maps=types.GoogleMaps())],\n",
        "      # Provide structured location.\n",
        "      tool_config=types.ToolConfig(retrieval_config=types.RetrievalConfig(\n",
        "            lat_lng=types.LatLng(\n",
        "                latitude=34.050481, longitude=-118.248526))),\n",
        "    )\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5AoiEtX9hJRT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "2cf576a3-cb0e-40a8-c967-407331d449b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Response\n Yes, there are several highly-rated cafes within a 20-minute walk that serve coffee, and some explicitly mention flat whites.\n\nHere are a few options:\n*   **Tiny Dancer Coffee** specifically mentions serving \"espressos and flat whites\" and has a rating of 4.8 stars. It's approximately a 6.8-minute walk from your current location (1.3 kilometers).\n*   **787 coffee** specializes in espresso drinks and lattes and boasts a 4.9-star rating. It's about a 7.6-minute walk away (1.7 kilometers).\n*   **Sote Coffee Roasters** has a 4.9-star rating and serves \"freshly roasted brews,\" suggesting high-quality coffee. This is about a 5.9-minute walk (1.5 kilometers).\n*   **White Noise Coffee - Coffee Shop & Roastery** has a 4.7-star rating and features \"globally sourced beans, roasted in-house,\" which is often a sign of good coffee. It's approximately a 5.0-minute walk (1.2 kilometers).\n*   **Cafe aroma** is very close, just a 1.6-minute walk (279 meters), and has a 4.7-star rating."
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Do any cafes around here do a good flat white? I will walk up to 20 minutes away\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        tools=[types.Tool(google_maps=types.GoogleMaps())],\n",
        "        tool_config=types.ToolConfig(\n",
        "            retrieval_config=types.RetrievalConfig(\n",
        "                lat_lng=types.LatLng(latitude=40.7680797, longitude=-73.9818957)\n",
        "            )\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "Markdown(f\"### Response\\n {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dewokmssn2-x"
      },
      "source": [
        "All grounded outputs require sources to be displayed after the response text. This code snippet will display the sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T3mktcrzoMCp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "30dfbde1-b105-45ed-d64a-14c806ea6bca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Sources from Google Maps\n- [Le Cafe Coffee](https://maps.google.com/?cid=3766819750231249954)\n- [White Noise Coffee - Coffee Shop & Roastery](https://maps.google.com/?cid=9563404650783060353)\n- [Tiny Dancer Coffee](https://maps.google.com/?cid=14421445427760414557)\n- [Heaven on 7th Marketplace](https://maps.google.com/?cid=13100894621228039586)"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "def generate_sources(response: types.GenerateContentResponse):\n",
        "  grounding = response.candidates[0].grounding_metadata\n",
        "  # You only need to display sources that were part of the grounded response.\n",
        "  supported_chunk_indices = {i for support in grounding.grounding_supports for i in support.grounding_chunk_indices}\n",
        "\n",
        "  sources = []\n",
        "  if supported_chunk_indices:\n",
        "    sources.append(\"### Sources from Google Maps\")\n",
        "  for i in supported_chunk_indices:\n",
        "    ref = grounding.grounding_chunks[i].maps\n",
        "    sources.append(f\"- [{ref.title}]({ref.uri})\")\n",
        "\n",
        "  return \"\\n\".join(sources)\n",
        "\n",
        "\n",
        "Markdown(generate_sources(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpf3yVOnoTTO"
      },
      "source": [
        "The response also includes data you can use to assemble in-line links. See the [Grounding with Google Search docs](https://ai.google.dev/gemini-api/docs/google-search#attributing_sources_with_inline_citations) for an example of this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i29-R5Y9ikuV"
      },
      "source": [
        "### Render the contextual Google Maps widget\n",
        "\n",
        "If you are building a web-based application, you can add an interactive widget that includes a map view, the contextual location, the places Gemini considered in the query, and review snippets.\n",
        "\n",
        "To load the widget, perform all of the following steps.\n",
        "1. [Acquire a Google Maps API key](https://developers.google.com/maps/documentation/javascript/get-api-key), enabled for the Places API and the Maps JavaScript API,\n",
        "1. Request the widget token in your request (with `GoogleMaps(enable_widget=True)`),\n",
        "1. [Load the Maps JavaScript API](https://developers.google.com/maps/documentation/javascript/load-maps-js-api) and enable the Places library,\n",
        "1. Render the [`<gmp-place-contextual/>`](https://developers.google.com/maps/documentation/javascript/reference/places-widget#PlaceContextualElement) element, setting `context-token` to the value of the `google_maps_widget_context_token` returned in the Gemini API response.\n",
        "\n",
        "Note that generating a widget can add additional latency to the response, so it is recommended that you do not enable the widget if you are not displaying it.\n",
        "\n",
        "Assuming you have a Google Maps API key with both APIs enabled, the following code shows one way to render the widget."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ijM8VHHhtrns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "fb8c9bf4-53bf-4c41-edf2-f6aa5399014a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret MAPS_API_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2015388838.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load or set your Maps API key here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mMAPS_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAPS_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# This is the same request as above, except `enable_widget` is set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret MAPS_API_KEY does not exist."
          ]
        }
      ],
      "source": [
        "\n",
        ")\n",
        "\n",
        "widget_token = response.candidates[0].grounding_metadata.google_maps_widget_context_token\n",
        "\n",
        "display(Markdown(f\"### Response\\n {response.text}\"))\n",
        "display(Markdown(generate_sources(response)))\n",
        "display(HTML(f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "  <body>\n",
        "    <div style=\"max-width: 500px; margin: 0 auto\">\n",
        "      <script src=\"https://maps.googleapis.com/maps/api/js?key={MAPS_API_KEY}&loading=async&v=alpha&libraries=places\" async></script>\n",
        "      <gmp-place-contextual context-token=\"{widget_token}\"></gmp-place-contextual>\n",
        "    </div>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZRCc8M947nK"
      },
      "source": [
        "Running and rendering the above code will require a Maps API key. Once you have it working, the widget will look like this.\n",
        "\n",
        "![Rendered contextual Places widget](https://storage.googleapis.com/generativeai-downloads/images/maps-widget.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XfNrFR7j6F6"
      },
      "source": [
        "## Grounding with YouTube links\n",
        "\n",
        "<a name=\"yt_links\"></a>\n",
        "\n",
        "You can directly include a public YouTube URL in your prompt. The Gemini models will then process the video content to perform tasks like summarization and answering questions about the content.\n",
        "\n",
        "This capability leverages Gemini's multimodal understanding, allowing it to analyze and interpret video data alongside any text prompts provided.\n",
        "\n",
        "You do need to explicitly declare the video URL you want the model to process as part of the contents of the request using a `FileData` part. Here a simple interaction where you ask the model to summarize a YouTube video:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "akVTribOkgT2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8f4b77ef-3ad0-4716-a88b-553553beda06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The video introduces \"Gemma Chess,\" a new application of Google's Gemma 3 language model designed to enhance the chess experience. Ju-yeong Ji from Google DeepMind explains that the goal isn't to replace powerful chess engines like AlphaZero or Stockfish, which excel at calculating optimal moves. Instead, Gemma aims to bring a \"new dimension\" to chess by leveraging its ability to understand and generate human-like text.\n\nKey applications of Gemma in chess include:\n1.  **Chess Explainer/Analysis:** Gemma can analyze chess games and provide understandable explanations for moves, strategies, and tactical ideas, rather than just raw engine evaluations. It can detail why a specific move is good, what the underlying strategic concepts are, and potential dangers, as demonstrated with a Kasparov vs. Deep Blue game.\n2.  **Storytelling:** The model can turn chess game data (moves, player information, tournament details) into engaging narratives, bringing historical or personal matches to life and making them more interesting to review.\n3.  **Personalized Learning:** Gemma acts as a \"super helpful study buddy\" or personal coach, explaining complex chess concepts (like the Sicilian Defense or passed pawns) in natural language, tailored to the user's skill level, and even in different languages (e.g., Korean). It can also provide feedback and suggest areas for improvement.\n\nBy combining the computational strength of traditional chess AI with Gemma's advanced linguistic abilities, this approach offers a more intuitive and human-centric way to learn, analyze, and appreciate the game of chess."
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "yt_link = \"https://www.youtube.com/watch?v=XV1kOFo1C8M\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"Summarize this video.\"),\n",
        "            types.Part(file_data=types.FileData(file_uri=yt_link)),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR7sQVlxy8Yr"
      },
      "source": [
        "But you can also use the link as the source of truth for your request. In this example, you will first ask how Gemma models can help on chess games:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTH4DqBAzx3H"
      },
      "outputs": [],
      "source": [
        "yt_link = \"https://www.youtube.com/watch?v=XV1kOFo1C8M\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(\n",
        "                text=\"In 2 paragraph, how Gemma models can help on chess games?\"\n",
        "            ),\n",
        "            types.Part(file_data=types.FileData(file_uri=yt_link)),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHhdfKqLz_D6"
      },
      "source": [
        "Now your answer is more insightful for the topic you want, using the knowledge shared on the video and not necessarily available on the model knowledge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKBPhxA-0RiT"
      },
      "source": [
        "## Grounding information using URL context\n",
        "\n",
        "<a name=\"url_context\"></a>\n",
        "\n",
        "The URL Context tool empowers Gemini models to directly access and process content from specific web page URLs you provide within your API requests. This is incredibly interesting because it allows your applications to dynamically interact with live web information without needing you to manually pre-process and feed that content to the model.\n",
        "\n",
        "URL Context is effective because it allows the models to base its responses and analysis directly on the content of the designated web pages. Instead of relying solely on its general training data or broad web searches (which are also valuable grounding tools), URL Context anchors the model's understanding to the specific information present at those URLs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7GrocBgYgrp"
      },
      "source": [
        "### Process website URLs\n",
        "\n",
        "If you want Gemini to specifically ground its answers thanks to the content of a specific website, just add the urls in your prompt and enable the tool by adding it to your config:\n",
        "```\n",
        "config = {\n",
        "  \"tools\": [\n",
        "    {\n",
        "      \"url_context\": {}\n",
        "    }\n",
        "  ],\n",
        "}\n",
        "```\n",
        "\n",
        "You can add up to 20 links in your prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOXM1Fh2D9Ai"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "  Based on https://ai.google.dev/gemini-api/docs/models, what are the key\n",
        "  differences between Gemini 1.5, Gemini 2.0 and Gemini 2.5 models?\n",
        "  Create a markdown table comparing the differences.\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"tools\": [{\"url_context\": {}}],\n",
        "}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    contents=[prompt], model=MODEL_ID, config=config\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPPCD5f2MSIx"
      },
      "source": [
        "You can see the status of the retrival using `url_context_metadata`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5kKeAX5MUsP"
      },
      "outputs": [],
      "source": [
        "# get URLs retrieved for context\n",
        "print(response.candidates[0].url_context_metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS2xyoMPY8u-"
      },
      "source": [
        "### Add PDFs by URL\n",
        "\n",
        "Gemini can also process PDFs from an URL. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeMZX5C5sLe3"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "  Can you give me an overview of the content of this pdf?\n",
        "  https://abc.xyz/assets/cc/27/3ada14014efbadd7a58472f1f3f4/2025q2-alphabet-earnings-release.pdf\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"tools\": [{\"url_context\": {}}],\n",
        "}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    contents=[prompt], model=MODEL_ID, config=config\n",
        ")\n",
        "\n",
        "display(Markdown(response.text.replace(\"$\", \"\\$\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAkMWXwAxiaT"
      },
      "source": [
        "### Add images by URL\n",
        "\n",
        "Gemini can also process images from an URL. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPNxQYkx8WJN"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "  Can you help me name of the numbered parts of that instrument, in French?\n",
        "  https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Trombone.svg/960px-Trombone.svg.png\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"tools\": [{\"url_context\": {}}],\n",
        "}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    contents=[prompt], model=MODEL_ID, config=config\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHs8FDfSsjt2"
      },
      "source": [
        "## Mix Search grounding and URL context\n",
        "\n",
        "The different tools can also be use in conjunction by adding them both to the config. It's a good way to steer Gemini in the right direction and then let it do its magic using search grounding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEOpBpbssjbD"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "  Can you give me an overview of the content of this pdf?\n",
        "  https://abc.xyz/assets/cc/27/3ada14014efbadd7a58472f1f3f4/2025q2-alphabet-earnings-release.pdf\n",
        "  Search on the web for the reaction of the main financial analysts, what's the trend?\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "  \"tools\": [\n",
        "      {\"url_context\": {}},\n",
        "      {\"google_search\": {}}\n",
        "  ],\n",
        "}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  contents=[prompt],\n",
        "  model=MODEL_ID,\n",
        "  config=config\n",
        ")\n",
        "\n",
        "display(Markdown(response.text.replace('$','\\$')))\n",
        "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOt32shZaEXj"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "<a name=\"next_steps\"></a>\n",
        "\n",
        "* For more details about using Google Search grounding, check out the [Search Grounding cookbook](./Search_Grounding.ipynb).\n",
        "* If you are looking for another scenarios using videos, take a look at the [Video understanding cookbook](./Video_understanding.ipynb).\n",
        "\n",
        "Also check the other Gemini capabilities that you can find in the [Gemini quickstarts](https://github.com/google-gemini/cookbook/tree/main/quickstarts/)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "Grounding.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}